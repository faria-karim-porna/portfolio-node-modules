{"ast":null,"code":"var _jsxFileName = \"C:\\\\Education\\\\Web Development\\\\Frontend\\\\React.js\\\\portfolio\\\\src\\\\Components\\\\Publications\\\\Publications.js\";\nimport React from \"react\";\nimport Navigation from \"../Navigation/Navigation\";\nimport PublicationsCard from \"../PublicationsCard/PublicationsCard\";\nimport SideNav from \"../SideNav/SideNav\";\nimport \"./Publications.css\";\n\nconst Publications = () => {\n  return /*#__PURE__*/React.createElement(\"div\", {\n    className: \"body\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 8,\n      columnNumber: 5\n    }\n  }, /*#__PURE__*/React.createElement(\"div\", {\n    className: \"side\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 9,\n      columnNumber: 7\n    }\n  }, /*#__PURE__*/React.createElement(SideNav, {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 10,\n      columnNumber: 9\n    }\n  })), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"main\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 12,\n      columnNumber: 7\n    }\n  }, /*#__PURE__*/React.createElement(Navigation, {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 13,\n      columnNumber: 9\n    }\n  }), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"container\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 14,\n      columnNumber: 9\n    }\n  }, /*#__PURE__*/React.createElement(\"p\", {\n    className: \"section-name\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 15,\n      columnNumber: 11\n    }\n  }, \"Publications\"), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"section-underline\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 16,\n      columnNumber: 11\n    }\n  }), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"row mt-4\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 17,\n      columnNumber: 11\n    }\n  }, /*#__PURE__*/React.createElement(PublicationsCard, {\n    title: \"Silent Speaker: A Lip-reading Model Using Deep Learning\",\n    description: \" In our model, we have tried to recognize speech without the presence or support \\r\\nof any auditory signal. We have only used the visual aspect of lip movement to detect the \\r\\nword. We have built our own dataset. We tracked the distance between the inner and outer \\r\\nlip to extract the features and LSTM is used to train the model. From this model, we got 43% \\r\\naccuracy.\",\n    type: \"Thesis\",\n    publicationDate: \"20.11.2020\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 18,\n      columnNumber: 13\n    }\n  }), /*#__PURE__*/React.createElement(PublicationsCard, {\n    title: \"Application of Fuzzy Logic on CT-Scan Images of COVID-19 Patients\",\n    description: \"We have used an image classification approach on CT-Scan and X-ray images \\r of COVID-19 patients. We have collected our dataset from multiple sources. Fuzzy c-means \\r and k-means clustering have been used to do the image segmentation. Then for \\r classification, segmented images and raw images are trained using the CNN model. From \\r our observation, we have noticed segmented images perform better than raw images. The \\r f1-score of our model is 91%.\",\n    type: \"Journal\",\n    publicationDate: \"08.09.2021\",\n    link: \"https://www.inderscienceonline.com/doi/abs/10.1504/IJIIDS.2021.118561\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 28,\n      columnNumber: 13\n    }\n  })))));\n};\n\nexport default Publications;","map":{"version":3,"sources":["C:/Education/Web Development/Frontend/React.js/portfolio/src/Components/Publications/Publications.js"],"names":["React","Navigation","PublicationsCard","SideNav","Publications"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB;AACA,OAAOC,UAAP,MAAuB,0BAAvB;AACA,OAAOC,gBAAP,MAA6B,sCAA7B;AACA,OAAOC,OAAP,MAAoB,oBAApB;AACA,OAAO,oBAAP;;AACA,MAAMC,YAAY,GAAG,MAAM;AACzB,sBACE;AAAK,IAAA,SAAS,EAAC,MAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACE;AAAK,IAAA,SAAS,EAAC,MAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACE,oBAAC,OAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,CADF,eAIE;AAAK,IAAA,SAAS,EAAC,MAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACE,oBAAC,UAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,eAEE;AAAK,IAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACE;AAAG,IAAA,SAAS,EAAC,cAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBADF,eAEE;AAAK,IAAA,SAAS,EAAC,mBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAFF,eAGE;AAAK,IAAA,SAAS,EAAC,UAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACE,oBAAC,gBAAD;AACE,IAAA,KAAK,EAAC,yDADR;AAEE,IAAA,WAAW,EAAC,4XAFd;AAOE,IAAA,IAAI,EAAC,QAPP;AAQE,IAAA,eAAe,EAAC,YARlB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,eAWE,oBAAC,gBAAD;AACE,IAAA,KAAK,EAAC,mEADR;AAEE,IAAA,WAAW,EAAC,0cAFd;AAQE,IAAA,IAAI,EAAC,SARP;AASE,IAAA,eAAe,EAAC,YATlB;AAUE,IAAA,IAAI,EAAC,uEAVP;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAXF,CAHF,CAFF,CAJF,CADF;AAuCD,CAxCD;;AA0CA,eAAeA,YAAf","sourcesContent":["import React from \"react\";\r\nimport Navigation from \"../Navigation/Navigation\";\r\nimport PublicationsCard from \"../PublicationsCard/PublicationsCard\";\r\nimport SideNav from \"../SideNav/SideNav\";\r\nimport \"./Publications.css\";\r\nconst Publications = () => {\r\n  return (\r\n    <div className=\"body\">\r\n      <div className=\"side\">\r\n        <SideNav></SideNav>\r\n      </div>\r\n      <div className=\"main\">\r\n        <Navigation></Navigation>\r\n        <div className=\"container\">\r\n          <p className=\"section-name\">Publications</p>\r\n          <div className=\"section-underline\"></div>\r\n          <div className=\"row mt-4\">\r\n            <PublicationsCard\r\n              title=\"Silent Speaker: A Lip-reading Model Using Deep Learning\"\r\n              description=\" In our model, we have tried to recognize speech without the presence or support \r\nof any auditory signal. We have only used the visual aspect of lip movement to detect the \r\nword. We have built our own dataset. We tracked the distance between the inner and outer \r\nlip to extract the features and LSTM is used to train the model. From this model, we got 43% \r\naccuracy.\"\r\n              type=\"Thesis\"\r\n              publicationDate=\"20.11.2020\"\r\n            ></PublicationsCard>\r\n            <PublicationsCard\r\n              title=\"Application of Fuzzy Logic on CT-Scan Images of COVID-19 Patients\"\r\n              description=\"We have used an image classification approach on CT-Scan and X-ray images \r\n              of COVID-19 patients. We have collected our dataset from multiple sources. Fuzzy c-means \r\n              and k-means clustering have been used to do the image segmentation. Then for \r\n              classification, segmented images and raw images are trained using the CNN model. From \r\n              our observation, we have noticed segmented images perform better than raw images. The \r\n              f1-score of our model is 91%.\"\r\n              type=\"Journal\"\r\n              publicationDate=\"08.09.2021\"\r\n              link=\"https://www.inderscienceonline.com/doi/abs/10.1504/IJIIDS.2021.118561\"\r\n            ></PublicationsCard>\r\n            {/* <PublicationsCard></PublicationsCard> */}\r\n          </div>\r\n        </div>\r\n      </div>\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default Publications;\r\n"]},"metadata":{},"sourceType":"module"}